<h2 align='center'>Ditto: Motion-Space Diffusion for Controllable Realtime Talking Head Synthesis</h2>


## ğŸ› ï¸ Installation

Tested Environment  
- System: Windows 10
- GPU: 3070  
- Python: 3.10
- CUDA: 12.4
- tensorRT: 8.6.1  


Clone the codes from [GitHub](https://github.com/justinjohn0306/ditto-talkinghead-windows):  
```bash
git clone https://github.com/justinjohn0306/ditto-talkinghead-windows
cd ditto-talkinghead
```


Create `conda` environment:
```bash
conda env create -f environment.yaml
conda activate ditto
```

## ğŸ“¥ Download Checkpoints

Download checkpoints from [HuggingFace](https://huggingface.co/justinjohn-03/ditto-talkinghead-windows) and put them in `checkpoints` dir:
```bash
git lfs install
git clone https://huggingface.co/justinjohn-03/ditto-talkinghead-windows checkpoints
```

The `checkpoints` should be like:
```text
./checkpoints/
â”œâ”€â”€ ditto_cfg
â”‚Â Â  â”œâ”€â”€ v0.4_hubert_cfg_trt.pkl
â”‚Â Â  â””â”€â”€ v0.4_hubert_cfg_trt_online.pkl
â”œâ”€â”€ plugins
â”‚Â Â  â”œâ”€â”€ grid_sample_3d_plugin.dll
â”‚Â Â  â””â”€â”€ libgrid_sample_3d_plugin.so
â”œâ”€â”€ ditto_onnx
â”‚Â Â  â”œâ”€â”€ appearance_extractor.onnx
â”‚Â Â  â”œâ”€â”€ blaze_face.onnx
â”‚Â Â  â”œâ”€â”€ decoder.onnx
â”‚Â Â  â”œâ”€â”€ face_mesh.onnx
â”‚Â Â  â”œâ”€â”€ hubert.onnx
â”‚Â Â  â”œâ”€â”€ insightface_det.onnx
â”‚Â Â  â”œâ”€â”€ landmark106.onnx
â”‚Â Â  â”œâ”€â”€ landmark203.onnx
â”‚Â Â  â”œâ”€â”€ libgrid_sample_3d_plugin.so
â”‚Â Â  â”œâ”€â”€ lmdm_v0.4_hubert.onnx
â”‚Â Â  â”œâ”€â”€ motion_extractor.onnx
â”‚Â Â  â”œâ”€â”€ stitch_network.onnx
â”‚Â Â  â””â”€â”€ warp_network.onnx
â””â”€â”€ ditto_trt_3090
    â”œâ”€â”€ appearance_extractor_fp16.engine
    â”œâ”€â”€ blaze_face_fp16.engine
    â”œâ”€â”€ decoder_fp16.engine
    â”œâ”€â”€ face_mesh_fp16.engine
    â”œâ”€â”€ hubert_fp32.engine
    â”œâ”€â”€ insightface_det_fp16.engine
    â”œâ”€â”€ landmark106_fp16.engine
    â”œâ”€â”€ landmark203_fp16.engine
    â”œâ”€â”€ lmdm_v0.4_hubert_fp32.engine
    â”œâ”€â”€ motion_extractor_fp32.engine
    â”œâ”€â”€ stitch_network_fp16.engine
    â””â”€â”€ warp_network_fp16.engine
```

- The `ditto_cfg/v0.4_hubert_cfg_trt_online.pkl` is online config
- The `ditto_cfg/v0.4_hubert_cfg_trt.pkl` is offline config


## ğŸš€ Inference 

Run `inference.py`:

```shell
python inference.py \
    --data_root "<path-to-trt-model>" \
    --cfg_pkl "<path-to-cfg-pkl>" \
    --audio_path "<path-to-input-audio>" \
    --source_path "<path-to-input-image>" \
    --output_path "<path-to-output-mp4>" 
```

For example:

```shell
python inference.py \
    --data_root "./checkpoints/ditto_trt_3090" \
    --cfg_pkl "./checkpoints/ditto_cfg/v0.4_hubert_cfg_trt.pkl" \
    --audio_path "./example/audio.wav" \
    --source_path "./example/image.png" \
    --output_path "./tmp/result.mp4" 
```

â—Note:

We have provided the tensorRT model with `hardware-compatibility-level=Ampere_Plus` (`checkpoints/ditto_trt_Ampere_Plus/`). If your GPU does not support it, please execute the `cvt_onnx_to_trt.py` script to convert from the general onnx model (`checkpoints/ditto_onnx/`) to the tensorRT model.

```bash
python scripts/cvt_onnx_to_trt.py --onnx_dir "./checkpoints/ditto_onnx" --trt_dir "./checkpoints/ditto_trt_custom"
```

Then run `inference.py` with `--data_root=./checkpoints/ditto_trt_custom`.


## ğŸ“§ Acknowledgement
This repo is forked from <b> justinjohn0306 </b> implementation of Ditto Talking-head on windows, which itself is based on Ant group's Ditto Talking Head repo.
Thanks for their remarkable contribution and released code! If we missed any open-source projects or related articles, we would like to complement the acknowledgement of this specific work immediately.

## âš–ï¸ License
This repository is released under the Apache-2.0 license as found in the [LICENSE](LICENSE) file.

## ğŸ“š Citation
If you find this codebase useful for your research, please use the following entry.
```BibTeX
@article{li2024ditto,
    title={Ditto: Motion-Space Diffusion for Controllable Realtime Talking Head Synthesis},
    author={Li, Tianqi and Zheng, Ruobing and Yang, Minghui and Chen, Jingdong and Yang, Ming},
    journal={arXiv preprint arXiv:2411.19509},
    year={2024}
}
```
